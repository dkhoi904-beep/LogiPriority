{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# 1. C√†i ƒë·∫∑t c√°c th∆∞ vi·ªán c·∫ßn thi·∫øt\n",
        "print(\"B·∫Øt ƒë·∫ßu c√†i ƒë·∫∑t th∆∞ vi·ªán...\")\n",
        "%pip install ultralytics gradio -q\n",
        "print(\"C√†i ƒë·∫∑t th√†nh c√¥ng!\")\n",
        "\n",
        "import gradio as gr\n",
        "from ultralytics import YOLO\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "# 2. Ki·ªÉm tra v√† t·∫£i m√¥ h√¨nh\n",
        "model_path = 'best.pt'\n",
        "if not os.path.exists(model_path):\n",
        "    raise FileNotFoundError(f\"Kh√¥ng t√¨m th·∫•y file '{model_path}'. Vui l√≤ng t·∫£i file model c·ªßa b·∫°n l√™n Colab.\")\n",
        "\n",
        "print(\"ƒêang t·∫£i m√¥ h√¨nh, vui l√≤ng ch·ªù...\")\n",
        "model = YOLO(model_path)\n",
        "print(\"T·∫£i m√¥ h√¨nh th√†nh c√¥ng!\")\n",
        "\n",
        "# 3. CH·ªàNH S·ª¨A T·∫†I ƒê√ÇY: √Ånh x·∫° ID v√† th√¥ng tin sinh vi√™n\n",
        "# !!! ƒê·∫¢M B·∫¢O TH·ª® T·ª∞ N√ÄY KH·ªöP V·ªöI FILE data.yaml C·ª¶A B·∫†N !!!\n",
        "student_info = {\n",
        "    0: \"V√¢n Anh - 31241024702\",\n",
        "    1: \"ƒêƒÉng Kh√¥i - 31241020719\",\n",
        "    2: \"Trung Hi·∫øu - 31241022719\"\n",
        "    # Th√™m c√°c th√†nh vi√™n kh√°c n·∫øu c√≥\n",
        "}\n",
        "\n",
        "# 4. H√†m x·ª≠ l√Ω v√† nh·∫≠n di·ªán\n",
        "def recognize_face(input_image):\n",
        "    if input_image is None:\n",
        "        return None, \"Vui l√≤ng t·∫£i ·∫£nh l√™n.\"\n",
        "\n",
        "    # Chuy·ªÉn ƒë·ªïi ·∫£nh ƒë·∫ßu v√†o sang ƒë·ªãnh d·∫°ng PIL.Image\n",
        "    image = Image.fromarray(input_image.astype('uint8'), 'RGB')\n",
        "\n",
        "    # Th·ª±c hi·ªán d·ª± ƒëo√°n\n",
        "    results = model(image, conf=0.5) # Ch·ªâ l·∫•y c√°c k·∫øt qu·∫£ c√≥ ƒë·ªô tin c·∫≠y > 50%\n",
        "    result = results[0]\n",
        "\n",
        "    # Ki·ªÉm tra xem c√≥ nh·∫≠n di·ªán ƒë∆∞·ª£c ai kh√¥ng\n",
        "    if len(result.boxes) == 0:\n",
        "        return input_image, \"Kh√¥ng nh·∫≠n di·ªán ƒë∆∞·ª£c khu√¥n m·∫∑t n√†o trong danh s√°ch.\"\n",
        "\n",
        "    # V·∫Ω bounding box v√† label l√™n ·∫£nh\n",
        "    # result.plot() tr·∫£ v·ªÅ ·∫£nh d·∫°ng BGR, c·∫ßn chuy·ªÉn sang RGB cho Gradio\n",
        "    annotated_image = result.plot()[..., ::-1]\n",
        "\n",
        "    # L·∫•y th√¥ng tin c·ªßa c√°c ƒë·ªëi t∆∞·ª£ng nh·∫≠n di·ªán ƒë∆∞·ª£c\n",
        "    output_texts = []\n",
        "    for box in result.boxes:\n",
        "        class_id = int(box.cls)\n",
        "        confidence = float(box.conf)\n",
        "        label = student_info.get(class_id, f\"Kh√¥ng r√µ (ID: {class_id})\")\n",
        "        output_texts.append(f\"- **{label}** (ƒê·ªô tin c·∫≠y: {confidence:.2f})\")\n",
        "\n",
        "    final_text = \"K·∫øt qu·∫£ nh·∫≠n di·ªán:\\n\" + \"\\n\".join(output_texts)\n",
        "\n",
        "    return annotated_image, final_text\n",
        "\n",
        "# 5. X√¢y d·ª±ng giao di·ªán\n",
        "with gr.Blocks(theme=gr.themes.Monochrome()) as demo:\n",
        "    gr.Markdown(\n",
        "        \"\"\"\n",
        "        # ü§ñ H·ªÜ TH·ªêNG NH·∫¨N DI·ªÜN TH√ÄNH VI√äN NH√ìM\n",
        "        T·∫£i l√™n m·ªôt b·ª©c ·∫£nh ƒë·ªÉ nh·∫≠n di·ªán th√†nh vi√™n v√† xem MSSV t∆∞∆°ng ·ª©ng.\n",
        "        \"\"\"\n",
        "    )\n",
        "    with gr.Row():\n",
        "        image_input = gr.Image(type=\"numpy\", label=\"·∫¢nh ƒë·∫ßu v√†o\")\n",
        "        with gr.Column():\n",
        "            image_output = gr.Image(label=\"K·∫øt qu·∫£\")\n",
        "            text_output = gr.Markdown()\n",
        "\n",
        "    btn = gr.Button(\"Nh·∫≠n di·ªán\", variant=\"primary\")\n",
        "    btn.click(fn=recognize_face, inputs=image_input, outputs=[image_output, text_output])\n",
        "\n",
        "    gr.Examples(\n",
        "        [[\"hieu.jpg\"], [\"khoi.jpg\"]], # Th√™m t√™n file ·∫£nh v√≠ d·ª• b·∫°n ƒë√£ t·∫£i l√™n Colab\n",
        "        inputs=image_input,\n",
        "        outputs=[image_output, text_output],\n",
        "        fn=recognize_face,\n",
        "        cache_examples=False\n",
        "    )\n",
        "\n",
        "\n",
        "# 6. Kh·ªüi ch·∫°y ·ª©ng d·ª•ng\n",
        "print(\"\\nƒêang kh·ªüi ch·∫°y giao di·ªán, vui l√≤ng ch·ªù m·ªôt l√°t...\")\n",
        "demo.launch(debug=True, share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Ky0hD6gEIBiO",
        "outputId": "15ac1cf6-cf11-4bc3-c622-2e4c46afc2a2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B·∫Øt ƒë·∫ßu c√†i ƒë·∫∑t th∆∞ vi·ªán...\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hC√†i ƒë·∫∑t th√†nh c√¥ng!\n",
            "Creating new Ultralytics Settings v0.0.6 file ‚úÖ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "ƒêang t·∫£i m√¥ h√¨nh, vui l√≤ng ch·ªù...\n",
            "T·∫£i m√¥ h√¨nh th√†nh c√¥ng!\n",
            "\n",
            "ƒêang kh·ªüi ch·∫°y giao di·ªán, vui l√≤ng ch·ªù m·ªôt l√°t...\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://c8e82539c09f358a87.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://c8e82539c09f358a87.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1436302145.py:35: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
            "  image = Image.fromarray(input_image.astype('uint8'), 'RGB')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 ƒêƒÉng Kh√¥i 31241020719, 49.1ms\n",
            "Speed: 27.5ms preprocess, 49.1ms inference, 315.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\u001b[KDownloading https://ultralytics.com/assets/Arial.Unicode.ttf to '/root/.config/Ultralytics/Arial.Unicode.ttf': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 22.2MB 109.1MB/s 0.2s\n",
            "\n",
            "0: 640x480 1 ƒêƒÉng Kh√¥i 31241020719, 46.3ms\n",
            "Speed: 11.0ms preprocess, 46.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1436302145.py:35: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
            "  image = Image.fromarray(input_image.astype('uint8'), 'RGB')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x480 1 ƒêƒÉng Kh√¥i 31241020719, 10.1ms\n",
            "Speed: 3.9ms preprocess, 10.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1436302145.py:35: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
            "  image = Image.fromarray(input_image.astype('uint8'), 'RGB')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://c8e82539c09f358a87.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. C√†i ƒë·∫∑t c√°c th∆∞ vi·ªán c·∫ßn thi·∫øt\n",
        "print(\"B·∫Øt ƒë·∫ßu c√†i ƒë·∫∑t th∆∞ vi·ªán...\")\n",
        "%pip install ultralytics gradio -q\n",
        "print(\"C√†i ƒë·∫∑t th√†nh c√¥ng!\")\n",
        "\n",
        "import gradio as gr\n",
        "from ultralytics import YOLO\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "# --- C·∫§U H√åNH C·ª¶A B·∫†N (ƒê·∫£m b·∫£o ch√≠nh x√°c) ---\n",
        "# T√™n file model YOLOv11 c·ªßa b·∫°n\n",
        "model_path = 'best.pt'\n",
        "\n",
        "# √Ånh x·∫° ID c·ªßa l·ªõp (class_id) v·ªõi th√¥ng tin sinh vi√™n\n",
        "# !!! ƒê·∫¢M B·∫¢O TH·ª® T·ª∞ N√ÄY KH·ªöP V·ªöI FILE data.yaml KHI B·∫†N TRAIN MODEL !!!\n",
        "student_info = {\n",
        "    0: \"V√¢n Anh - MSSV:31241024702 - Qu√™ qu√°n: Ki√™n Giang - Sinh vi√™n nƒÉm 2 ng√†nh C√¥ng ngh·ªá Logistics ƒê·∫°i h·ªçc Kinh t·∫ø TP.HCM\",\n",
        "    1: \"ƒêƒÉng Kh√¥i - MSSV:31241020719 - Qu√™ qu√°n: TP.HCM - Sinh vi√™n nƒÉm 2 ng√†nh C√¥ng ngh·ªá Logistics ƒê·∫°i h·ªçc Kinh t·∫ø TP.HCM\",\n",
        "    2: \"Trung Hi·∫øu MSSV:31241022719 - Qu√™ qu√°n: An Giang - Sinh vi√™n nƒÉm 2 ng√†nh C√¥ng ngh·ªá Logistics ƒê·∫°i h·ªçc Kinh t·∫ø TP.HCM\"\n",
        "}\n",
        "# --- K·∫æT TH√öC C·∫§U H√åNH C·ª¶A B·∫†N ---\n",
        "\n",
        "# 2. Ki·ªÉm tra v√† t·∫£i m√¥ h√¨nh\n",
        "print(\"ƒêang t·∫£i m√¥ h√¨nh, vui l√≤ng ch·ªù...\")\n",
        "try:\n",
        "    if not os.path.exists(model_path):\n",
        "        raise FileNotFoundError(f\"Kh√¥ng t√¨m th·∫•y file '{model_path}'. Vui l√≤ng t·∫£i file model c·ªßa b·∫°n l√™n Colab.\")\n",
        "    model = YOLO(model_path)\n",
        "    print(\"T·∫£i m√¥ h√¨nh th√†nh c√¥ng!\")\n",
        "except Exception as e:\n",
        "    print(f\"L·ªói khi t·∫£i m√¥ h√¨nh: {e}. Vui l√≤ng ki·ªÉm tra l·∫°i ƒë∆∞·ªùng d·∫´n ho·∫∑c file.\")\n",
        "    print(\"S·ª≠ d·ª•ng m√¥ h√¨nh YOLOv8n m·∫∑c ƒë·ªãnh ƒë·ªÉ ti·∫øp t·ª•c demo.\")\n",
        "    model = YOLO('yolov8n.pt')\n",
        "\n",
        "# 3. H√†m x·ª≠ l√Ω v√† nh·∫≠n di·ªán\n",
        "def recognize_face(input_image):\n",
        "    if input_image is None:\n",
        "        # Tr·∫£ v·ªÅ placeholder tr·ªëng v√† th√¥ng b√°o h∆∞·ªõng d·∫´n\n",
        "        return None, \"<p style='text-align: center; color: #888;'>Vui l√≤ng t·∫£i ·∫£nh l√™n v√† nh·∫•n n√∫t 'Nh·∫≠n Di·ªán'</p>\"\n",
        "\n",
        "    image = Image.fromarray(input_image.astype('uint8'), 'RGB')\n",
        "    results = model(image, conf=0.5)\n",
        "    result = results[0]\n",
        "\n",
        "    if len(result.boxes) == 0:\n",
        "        # Tr·∫£ v·ªÅ ·∫£nh g·ªëc v√† th√¥ng b√°o kh√¥ng t√¨m th·∫•y\n",
        "        return input_image, \"<h3 style='color: #d9534f;'>Kh√¥ng t√¨m th·∫•y khu√¥n m·∫∑t n√†o trong danh s√°ch nh·∫≠n di·ªán.</h3>\"\n",
        "\n",
        "    annotated_image = result.plot()[..., ::-1]\n",
        "\n",
        "    output_texts = []\n",
        "    for box in result.boxes:\n",
        "        class_id = int(box.cls)\n",
        "        confidence = float(box.conf)\n",
        "        label = student_info.get(class_id, f\"Kh√¥ng r√µ (ID: {class_id})\")\n",
        "        output_texts.append(f\"<li><b>{label}</b> (ƒê·ªô tin c·∫≠y: {confidence:.2f})</li>\")\n",
        "\n",
        "    final_text = \"<h3>‚ú® K·∫øt qu·∫£ nh·∫≠n di·ªán:</h3><ul>\" + \"\".join(output_texts) + \"</ul>\"\n",
        "\n",
        "    return annotated_image, final_text\n",
        "\n",
        "# 4. X√¢y d·ª±ng giao di·ªán v·ªõi Gradio\n",
        "with gr.Blocks(theme=gr.themes.Soft(), title=\"FaceDetecting - Nh·∫≠n Di·ªán Th√†nh Vi√™n Nh√≥m\") as demo:\n",
        "    gr.Markdown(\n",
        "        \"\"\"\n",
        "        <h1 style=\"text-align: center; color: #4CAF50;\">‚ú® FaceDetecting ‚ú®</h1>\n",
        "        <p style=\"text-align: center; font-size: 1.1em; color: #555;\">\n",
        "            H·ªá th·ªëng nh·∫≠n di·ªán th√†nh vi√™n nh√≥m c·ªßa ch√∫ng t√¥i (V√¢n Anh, ƒêƒÉng Kh√¥i, Trung Hi·∫øu)\n",
        "            v√† hi·ªÉn th·ªã th√¥ng tin MSSV t∆∞∆°ng ·ª©ng.\n",
        "        </p>\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=1):\n",
        "            image_input = gr.Image(type=\"numpy\", label=\"·∫¢nh ƒê·∫ßu V√†o\", height=350)\n",
        "            btn = gr.Button(\"üöÄ Nh·∫≠n Di·ªán Khu√¥n M·∫∑t\", variant=\"primary\")\n",
        "\n",
        "        with gr.Column(scale=1):\n",
        "            gr.Markdown(\"<h3 style='text-align: center; color: #333;'>K·∫øt Qu·∫£ Nh·∫≠n Di·ªán</h3>\")\n",
        "\n",
        "            # === S·ª¨A L·ªñI T·∫†I ƒê√ÇY ===\n",
        "            # Th√™m 'interactive=False' ƒë·ªÉ √¥ k·∫øt qu·∫£ ch·ªâ hi·ªÉn th·ªã, kh√¥ng cho ph√©p t·∫£i l√™n.\n",
        "            image_output = gr.Image(label=\"·∫¢nh ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω\", interactive=False, height=350)\n",
        "            text_output = gr.HTML(label=\"Th√¥ng tin chi ti·∫øt\")\n",
        "\n",
        "    # Li√™n k·∫øt n√∫t b·∫•m v·ªõi h√†m x·ª≠ l√Ω\n",
        "    btn.click(fn=recognize_face, inputs=image_input, outputs=[image_output, text_output])\n",
        "\n",
        "    gr.Markdown(\"<h3 style='text-align: center; color: #333; margin-top: 30px;'>Th·ª≠ V·ªõi C√°c V√≠ D·ª• C√≥ S·∫µn</h3>\")\n",
        "    gr.Examples(\n",
        "        examples=[\n",
        "            [\"/content/Vanh.jpg\"], # Thay b·∫±ng link ·∫£nh th·∫≠t\n",
        "            [\"/content/Kh√¥i.jpg\"], # Thay b·∫±ng link ·∫£nh th·∫≠t\n",
        "            [\"/content/Hi·∫øu.jpg\"]  # Thay b·∫±ng link ·∫£nh th·∫≠t\n",
        "        ],\n",
        "        inputs=image_input,\n",
        "        outputs=[image_output, text_output],\n",
        "        fn=recognize_face,\n",
        "        cache_examples=False,\n",
        "        label=\"Ch·ªçn m·ªôt ·∫£nh ƒë·ªÉ xem k·∫øt qu·∫£ nhanh\"\n",
        "    )\n",
        "\n",
        "    gr.Markdown(\n",
        "        \"\"\"\n",
        "        <p style=\"text-align: center; font-size: 0.8em; color: #999; margin-top: 50px;\">\n",
        "            ¬© 2024 Nh√≥m XYZ - Powered by YOLOv11 & Gradio\n",
        "        </p>\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "# 5. Kh·ªüi ch·∫°y ·ª©ng d·ª•ng\n",
        "print(\"\\nƒêang kh·ªüi ch·∫°y giao di·ªán, vui l√≤ng ch·ªù m·ªôt l√°t...\")\n",
        "demo.launch(debug=True, share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 975
        },
        "id": "E4MxIaU5MzN6",
        "outputId": "2d23a2c1-0871-492d-c52c-b8a4024285a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B·∫Øt ƒë·∫ßu c√†i ƒë·∫∑t th∆∞ vi·ªán...\n",
            "C√†i ƒë·∫∑t th√†nh c√¥ng!\n",
            "ƒêang t·∫£i m√¥ h√¨nh, vui l√≤ng ch·ªù...\n",
            "T·∫£i m√¥ h√¨nh th√†nh c√¥ng!\n",
            "\n",
            "ƒêang kh·ªüi ch·∫°y giao di·ªán, vui l√≤ng ch·ªù m·ªôt l√°t...\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://fdbfa8ddfb6ada6974.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://fdbfa8ddfb6ada6974.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3479494814.py:42: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
            "  image = Image.fromarray(input_image.astype('uint8'), 'RGB')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: 640x480 1 ƒêƒÉng Kh√¥i 31241020719, 47.0ms\n",
            "Speed: 3.8ms preprocess, 47.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 1 ƒêƒÉng Kh√¥i 31241020719, 8.2ms\n",
            "Speed: 3.0ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 480)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3479494814.py:42: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
            "  image = Image.fromarray(input_image.astype('uint8'), 'RGB')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 ƒêƒÉng Kh√¥i 31241020719, 50.2ms\n",
            "Speed: 2.2ms preprocess, 50.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3479494814.py:42: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
            "  image = Image.fromarray(input_image.astype('uint8'), 'RGB')\n"
          ]
        }
      ]
    }
  ]
}